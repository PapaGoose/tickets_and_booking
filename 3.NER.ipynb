{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb2cc74-5937-4193-b88b-196d677973e6",
   "metadata": {},
   "source": [
    "# Тестирование in-context learning для Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b3e9908-b472-4090-9f85-2760086bdb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-07 18:37:27 llm_engine.py:70] Initializing an LLM engine with config: model='mistralai/Mistral-7B-Instruct-v0.2', tokenizer='mistralai/Mistral-7B-Instruct-v0.2', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, enforce_eager=False, seed=0)\n",
      "INFO 04-07 18:37:38 llm_engine.py:275] # GPU blocks: 12690, # CPU blocks: 2048\n",
      "INFO 04-07 18:37:39 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 04-07 18:37:39 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.\n",
      "INFO 04-07 18:37:41 model_runner.py:547] Graph capturing finished in 3 secs.\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "from tqdm import tqdm\n",
    "\n",
    "llm = LLM(model=\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0421180b-a6d0-43ad-8eaf-f4d0bc5aeb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_csv('Data/generated_data.csv')\n",
    "df.json = df.json.apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b65a66-6c81-4f99-9d3f-29bd848c0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "ner = NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c75e65-0ba6-4948-88c8-8c8f8b3cdd7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [56:59<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "sampling_params = SamplingParams(temperature=0, max_tokens=100, stop='}', include_stop_str_in_output=True)\n",
    "\n",
    "for i in tqdm(range(2000)):\n",
    "    sample = df.iloc[i]\n",
    "    prompt = f\"\"\"Ты должен найти в тексте определенные атрибуты и сохранить их в формате JSON. Не используй комментарии.\n",
    "    \n",
    "    Используй следующий шаблон:\n",
    "    \n",
    "    Текст: сообщение пользователя в чате.\n",
    "    JSON: объект по всем стандартам JSON.{ner.label_mapping[sample.label]['template']}\n",
    "    Начинай!\n",
    "    \n",
    "    Текст: {sample.text}\n",
    "    JSON:\"\"\"\n",
    "    \n",
    "    output = llm.generate(prompt, sampling_params, use_tqdm=False)[0]\n",
    "        \n",
    "    # Print the outputs.\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    ner.count_errors(sample, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "339555d2-58c9-4686-96ba-675563b21abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность для класса \"самолет\"\n",
      "\n",
      "\tdeparture_city: 0.77300\n",
      "\n",
      "\tarrival_city: 0.89900\n",
      "\n",
      "\tdeparture_date: 0.80300\n",
      "\n",
      "\treturn_date: 0.88500\n",
      "\n",
      "Точность для класса \"отель\"\n",
      "\n",
      "\tcity: 0.49300\n",
      "\n",
      "\thotel: 0.71400\n",
      "\n",
      "\tdate: 0.28500\n",
      "\n",
      "\tguests: 0.70800\n",
      "\n",
      "\tdays: 0.48800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ner.score()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdca31-a2bb-4416-ab90-132837a56620",
   "metadata": {},
   "source": [
    "__Вывод:__\n",
    "Модель с трудом определяет верные даты и числа, однако с названиями городов и отелей справляется хорошо.\n",
    "\n",
    "__Дальнейшие шаги:__\n",
    "Необходимо дообучить модель на задачу NER используя 80% данных. Предварительно нужно замерить точность на тестовой выборке, чтобы сравнить улучшение результата после тренировки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb2f89-a2c6-4467-8197-a12233fdf0d0",
   "metadata": {},
   "source": [
    "# Точность на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e3e928-d235-4dd7-8dd0-e9cfcd81c1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0, max_tokens=100, stop='}', include_stop_str_in_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e967d22-e1d3-4e77-817f-922765d12a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ner = NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a9c8f7-8d9f-444f-b788-1b387f1f648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([df.iloc[800:1000], df.iloc[1800:2000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5471b01-3a09-407a-baeb-b09bfc5e5558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [11:24<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(400)):\n",
    "    sample = test_df.iloc[i]\n",
    "    prompt = f\"\"\"Ты должен найти в тексте определенные атрибуты и сохранить их в формате JSON. Не используй комментарии.\n",
    "\n",
    "Используй следующий шаблон:\n",
    "\n",
    "Текст: сообщение пользователя в чате.\n",
    "JSON: объект по всем стандартам JSON.{test_ner.label_mapping[sample.label]['template']}\n",
    "Начинай!\n",
    "\n",
    "Текст: {sample.text}\n",
    "Ответ:\"\"\"\n",
    "    \n",
    "    output = llm.generate(prompt, sampling_params, use_tqdm=False)[0]\n",
    "        \n",
    "    # Print the outputs.\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    test_ner.count_errors(sample, generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81066c7c-7fda-4a8d-9e71-5da7a527bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность для класса \"самолет\"\n",
      "\n",
      "\tdeparture_city: 0.78500\n",
      "\n",
      "\tarrival_city: 0.90000\n",
      "\n",
      "\tdeparture_date: 0.79000\n",
      "\n",
      "\treturn_date: 0.86500\n",
      "\n",
      "Точность для класса \"отель\"\n",
      "\n",
      "\tcity: 0.47000\n",
      "\n",
      "\thotel: 0.80500\n",
      "\n",
      "\tdate: 0.27000\n",
      "\n",
      "\tguests: 0.82000\n",
      "\n",
      "\tdays: 0.51000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_ner.score()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
